import os
import json
import logging
import time
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
try:
    from openai import OpenAI
except Exception:  # pragma: no cover
    OpenAI = None  # will error at runtime if missing

from models import (
    FormAnalysisResponse, AnalyzeRequest, FormData,
    ElementCategory, ComplexityLevel, PainPoint, Benefit, Priority
)

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

load_dotenv()
MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o")

app = FastAPI(title="CM Form PD ‚Äì AI Proxy", version="1.0.0")

# Log au d√©marrage
@app.on_event("startup")
async def startup_event():
    logger.info("=" * 80)
    logger.info("üöÄ BACKEND D√âMARR√â")
    logger.info("=" * 80)
    logger.info(f"Mod√®le OpenAI: {MODEL}")
    logger.info(f"API Key pr√©sente: {'‚úÖ' if os.environ.get('OPENAI_API_KEY') else '‚ùå'}")
    logger.info("Endpoints disponibles:")
    logger.info("  - GET  /health")
    logger.info("  - POST /ai")
    logger.info("  - POST /analyze (Structured Outputs)")
    logger.info("=" * 80 + "\n")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class AiRequest(BaseModel):
    prompt: str


class AiResponse(BaseModel):
    text: str


@app.get("/health")
def health():
    return {"ok": True, "model": MODEL}


@app.post("/ai", response_model=AiResponse)
async def ai(req: AiRequest):
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY manquant dans l'environnement")
    if OpenAI is None:
        raise HTTPException(status_code=500, detail="Package openai manquant. Installez-le via requirements.txt")

    try:
        client = OpenAI(api_key=api_key)
        resp = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "Tu es un assistant expert en design de processus et delivery produit."},
                {"role": "user", "content": req.prompt},
            ],
            temperature=0.2,
            max_tokens=900,
        )
        text = (resp.choices[0].message.content or "").strip()
        return AiResponse(text=text)
    except Exception as e:
        raise HTTPException(status_code=502, detail=str(e))


@app.post("/analyze", response_model=FormAnalysisResponse)
async def analyze_form(req: AnalyzeRequest):
    """
    Analyse structur√©e du formulaire avec Structured Outputs.
    Garantit une structure JSON fixe et des cat√©gories strictes.
    """
    logger.info("=" * 80)
    logger.info("üì• NOUVELLE REQU√äTE D'ANALYSE")
    logger.info("=" * 80)
    
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY manquant")
    if OpenAI is None:
        raise HTTPException(status_code=500, detail="Package openai manquant")

    # Construire le prompt contextuel
    d = req.form_data
    logger.info(f"üìã Donn√©es formulaire re√ßues:")
    logger.info(f"   - Persona: {d.q1} {d.q2} ({d.q3} - {d.q4})")
    logger.info(f"   - Brief: {(d.q5 or '')[:100]}...")
    logger.info(f"   - Volum√©trie: {d.q7} / {d.q8} exec / {d.q9} unitaire")
    
    context = f"""
CONTEXTE FORMULAIRE - ANALYSE PROCESS DESIGNER

=== PERSONA ===
Nom: {d.q1 or '-'} {d.q2 or '-'}
R√¥le: {d.q3 or '-'}
D√©partement: {d.q4 or '-'}

=== BESOIN ===
Brief utilisateur:
{d.q5 or '-'}

Ex√©cution actuelle:
{d.q6 or '-'}

=== VOLUM√âTRIE ===
Fr√©quence: {d.q7 or '-'}
Nb ex√©cutions/occurrence: {d.q8 or '-'}
Temps unitaire: {d.q9 or '-'}
Nb personnes: {d.q10 or '-'}
Irritant: {d.q11 or '3'}/5
Pourquoi irritant: {d.q11a or '-'}
Pourquoi urgent: {d.q11b or '-'}

=== NATURE T√ÇCHE ===
√âl√©ments sources: {d.q12 or '-'}
Action manuelle: {d.q13 or '-'}
Exemple action: {d.q13a or '-'}
R√®gles simples: {d.q14 or '-'}
Exemple complexit√©: {d.q14a or '-'}
Complexit√© orga: {d.q15 or '-'}
Outils: {d.q16 or '-'}

=== INSTRUCTIONS ===
1. USER STORY: G√©n√®re une user story HTML concise (max 100 mots) avec ce format EXACT:
   <p><strong>En tant que</strong> [r√¥le],</p>
   <p><strong>j'ai besoin de</strong> [besoin d√©taill√©]</p>
   <p><strong>afin de</strong> [b√©n√©fice concret].</p>
   
   IMPORTANT: Utilise des balises <p> pour chaque partie et <strong> uniquement sur "En tant que", "j'ai besoin de", "afin de".

2. EXECUTION SCHEMA: 
   - Cr√©e un diagramme ASCII vertical avec les caract√®res: ‚îå‚îÄ‚îê‚îÇ‚îî‚îò et ‚ñº
   - Liste les √©tapes extraites de "Ex√©cution actuelle"
   
3. ELEMENTS SOURCES:
   - Analyse "√âl√©ments sources" et cat√©gorise STRICTEMENT avec les cat√©gories pr√©d√©finies
   - Compte le nombre de types diff√©rents
   - D√©termine le niveau de complexit√© (Structur√©/Semi-structur√©/Non-structur√©)

4. ANALYSIS:
   - Extrais les pain points du brief (UNIQUEMENT parmi la liste pr√©d√©finie)
   - Identifie les b√©n√©fices (UNIQUEMENT parmi la liste pr√©d√©finie)
   - Calcule un score de faisabilit√© 0-100 bas√© sur: r√®gles simples (+30), donn√©es structur√©es (+30), complexit√© orga simple (+20), peu d'actions manuelles (+20)
   - D√©termine la priorit√©: >70 = Quick win, 45-70 = √Ä challenger, <45 = Long shot
"""

    try:
        client = OpenAI(api_key=api_key)
        
        # V√©rifier que le mod√®le supporte Structured Outputs
        if MODEL not in ["gpt-4o", "gpt-4o-mini", "gpt-4o-2024-08-06"]:
            raise HTTPException(
                status_code=400, 
                detail=f"Mod√®le {MODEL} ne supporte pas Structured Outputs. Utilisez gpt-4o ou gpt-4o-mini"
            )
        
        # G√©n√©rer le sch√©ma JSON
        schema = FormAnalysisResponse.model_json_schema()
        
        logger.info("\n" + "=" * 80)
        logger.info("ü§ñ APPEL OPENAI")
        logger.info("=" * 80)
        logger.info(f"Mod√®le: {MODEL}")
        system_prompt = "Tu es un expert en analyse de processus m√©tier et automatisation. Tu dois analyser un formulaire et produire une r√©ponse JSON STRICTEMENT conforme au sch√©ma fourni. Utilise UNIQUEMENT les cat√©gories pr√©d√©finies dans les enums."
        
        logger.info(f"\nüì§ MESSAGES ENVOY√âS √Ä OPENAI:")
        logger.info("-" * 80)
        logger.info(f"SYSTEM: {system_prompt}")
        logger.info("")
        logger.info(f"USER:\n{context}")
        logger.info("-" * 80)
        logger.info("\n‚è≥ Appel OpenAI en cours...")
        
        # Chronom√®tre
        start_time = time.time()
        
        # Appel avec Structured Outputs
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": context
                }
            ],
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "form_analysis_response",
                    "strict": True,
                    "schema": schema
                }
            },
            temperature=0.3,
            max_tokens=2000
        )
        
        # Temps √©coul√©
        elapsed = time.time() - start_time
        logger.info(f"‚úÖ R√©ponse OpenAI re√ßue en {elapsed:.2f}s")
        
        # Tokens utilis√©s
        if hasattr(response, 'usage') and response.usage:
            logger.info(f"üìä Tokens utilis√©s:")
            logger.info(f"   - Prompt: {response.usage.prompt_tokens}")
            logger.info(f"   - Completion: {response.usage.completion_tokens}")
            logger.info(f"   - Total: {response.usage.total_tokens}")
        
        # Parse et valide avec Pydantic
        content = response.choices[0].message.content
        if not content:
            raise ValueError("R√©ponse OpenAI vide")
        
        logger.info("\nüì• R√âPONSE OPENAI (JSON):")
        logger.info("-" * 80)
        # Pretty print du JSON
        try:
            formatted_json = json.dumps(json.loads(content), indent=2, ensure_ascii=False)
            logger.info(formatted_json)
        except:
            logger.info(content)
        logger.info("-" * 80)
        
        # Parse JSON
        result_json = json.loads(content)
        logger.info("\n‚úÖ JSON pars√© avec succ√®s")
        logger.info(f"üìä Aper√ßu:")
        logger.info(f"   - User story: {result_json.get('user_story', {}).get('word_count', 0)} mots")
        logger.info(f"   - √âtapes: {len(result_json.get('execution_schema', {}).get('steps', []))}")
        logger.info(f"   - √âl√©ments sources: {result_json.get('elements_sources', {}).get('count', 0)} types")
        logger.info(f"   - Complexit√©: {result_json.get('elements_sources', {}).get('complexity_level', '?')}")
        logger.info(f"   - Faisabilit√©: {result_json.get('analysis', {}).get('feasibility_score', 0)}/100")
        logger.info(f"   - Priorit√©: {result_json.get('analysis', {}).get('priority', '?')}")
        
        # Validation Pydantic
        validated_result = FormAnalysisResponse(**result_json)
        logger.info("\n‚úÖ Validation Pydantic OK")
        logger.info("=" * 80 + "\n")
        
        return validated_result
        
    except HTTPException:
        raise
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Erreur parsing JSON: {str(e)}")
        raise HTTPException(status_code=502, detail=f"Erreur parsing JSON: {str(e)}")
    except Exception as e:
        # Log d√©taill√© de l'erreur
        import traceback
        logger.error("‚ùå ERREUR OPENAI:")
        logger.error(traceback.format_exc())
        error_detail = f"Erreur OpenAI: {str(e)}"
        raise HTTPException(status_code=502, detail=error_detail)


